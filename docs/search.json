[
  {
    "objectID": "questao2.html",
    "href": "questao2.html",
    "title": "Questão 2",
    "section": "",
    "text": "Nesta seção, exploraremos dados referentes a 27 estabelecimentos industriais. Tentaremos explicar o número de supervisores em função do número de trabalhadores desses estabelecimentos.\nAs primeiras seis linhas desse conjunto de dados são expostos na tabela a seguir.\nCode\npacman::p_load(tidyverse, tidymodels, cowplot)\n\nsupervisores &lt;- read.table(\"supervisores.txt\", header = TRUE)\n\nhead(supervisores, 6) %&gt;%\n  select(nsupervisores, ntrabalhadores) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 2\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\nnsupervisores\nntrabalhadores\n\n\n\n\n30\n294\n\n\n32\n247\n\n\n37\n267\n\n\n44\n358\n\n\n47\n423\n\n\n49\n311"
  },
  {
    "objectID": "questao2.html#análise-exploratória",
    "href": "questao2.html#análise-exploratória",
    "title": "Questão 2",
    "section": "Análise exploratória",
    "text": "Análise exploratória\nIniciamos a análise exploratória com a inspeção visual do gráfico de dispersão entre a variável resposta, nsupervisores, e a variável explicativa, ntrabalhadores.\nÉ notável uma dispersão em formato de cone, o que sugere heteroscedasticidade da variável resposta.\n\n\nCode\nggplot(supervisores, aes(nsupervisores, ntrabalhadores))+\n  geom_point()+\n  labs(x = \"Trabalhadores\", y = \"Supervisores\") +\n  theme_bw()\n\n\n\n\n\nAlém disso, é possível observar que as distribuições parecem razoavelmente simétricas, porém com leve assimetria positiva. O número de trabalhadores (20500) também é muito superior ao de supervisores (2550), havendo em média 8 trabalhadores por supervisor. Essa razão tem limite entre 6.2 e 12.2.\n\n\nCode\nsupervisores %&gt;%\n  select(\"Supervisores\" = nsupervisores, \"Trabalhadores\" = \"ntrabalhadores\") %&gt;%\n  pivot_longer(cols = everything()) %&gt;%\n  ggplot(aes(name, value))+\n  geom_boxplot()+\n  stat_summary(fun=mean, geom=\"point\", shape=5, size=2, color=\"black\", fill=\"gray\")+\n  theme_minimal()+\n  theme(axis.title = element_blank())"
  },
  {
    "objectID": "questao2.html#ajuste-de-modelo",
    "href": "questao2.html#ajuste-de-modelo",
    "title": "Questão 2",
    "section": "Ajuste de Modelo",
    "text": "Ajuste de Modelo\n\n\nCode\nfit &lt;- lm(nsupervisores ~ ntrabalhadores, data = supervisores)\n\n\nAjustamos um modelo de regressão linear simples usando a função lm(), cujos estimadores e suas características são espostos a seguir. O coeficiente de determinação do modelo é R^2= 0.78.\n\n\nCode\ntidy(fit) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 4,\n    col.names = c(\"\", \"Estimador\", \"Erro P.\", \"t\", \"p-valor\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\n\nEstimador\nErro P.\nt\np-valor\n\n\n\n\n(Intercept)\n14.4481\n9.5620\n1.5110\n0.1433\n\n\nntrabalhadores\n0.1054\n0.0113\n9.3029\n0.0000\n\n\n\n\n\n\n\n\n\nCode\nnormalidade &lt;- shapiro.test(fit$residuals)\n\n\nO estimador do modelo tem as suas características dispostas na tabela a seguir. O coeficiente de determinação do modelo é de R^2= 0.78, ou seja, 78% da variação da variável resposta pode ser explicada pela variável explicativa.\n\n\nCode\ntidy(fit) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 4,\n    col.names = c(\"\", \"Estimador\", \"Erro P.\", \"t\", \"p-valor\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\n\nEstimador\nErro P.\nt\np-valor\n\n\n\n\n(Intercept)\n14.4481\n9.5620\n1.5110\n0.1433\n\n\nntrabalhadores\n0.1054\n0.0113\n9.3029\n0.0000\n\n\n\n\n\n\n\nNo entanto, este coeficiente seria aplicável a um modelo com resíduos homocedásticos e com distribuição normal. Visualmente, já se trata de um modelo com resíduos heteroscedásticos porém, mediante aplicação de teste Shapiro-Wilk, obtém-se p-valor de 0.2, não sugerindo rejeição da normalidade.\n\nAnálise de resíduos Studentizados\nSe montarmos um gráfico de resposta versus resíduos Studentizados vemos novamente indícios para resíduos heteroscedásticos.\n\n\nCode\ntibble(\n  ajustados = fitted(fit),\n  res_stu = stats::rstudent(fit)\n) %&gt;%\n  ggplot(aes(ajustados, res_stu))+\n  geom_point() +\n  theme_bw()+\n  labs(x = \"Resposta ajustada\", y = \"Resíduos Studentizados\")\n\n\n\n\n\n\n\nAvaliação de normalidade da resposta\nUma análise visual do gráfico dos resíduos Studentizados versus quantis da normal demonstram um padrão periódico com diversos pontos fora da banda de confiança. Contrariamente ao teste Shapiro-Wilk, esta avaliação sugere fuga da suposição de normalidade.\n\n\nCode\nsource(\"envelope_function.R\")\n\nenvelope_LR(fit, OLS = T, main.title = \"Gráfico dos resíduos com envelope\")\n\n\n\n\n\n\n\nModelos sob Mínimos Quadrados Ponderados\nNesta seção supomos que Var(Y) = \\sigma^2 V, com V = diag\\{x_1^p, x_2^p, \\dots, x_n^p\\}, com p = 1, 2, 3. Ou seja, serão ajustados três modelos, transformações do modelo original, decompondo via Cholesky a matriz V = PP^\\top. O novo modelo é dado por\n\nP^{-1}Y = P^{-1}X\\beta + P^{-1}\\varepsilon \\quad \\Rightarrow \\quad Z = Q\\beta + \\eta\n\nDe fato,\n\nX = \\begin{bmatrix}\n1 & x_1\\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix} \\quad \\Rightarrow \\quad Q = \\begin{bmatrix}\n\\frac{1}{\\sqrt{x_1^p}} & \\frac{x_1}{\\sqrt{x_1^p}}\\\\\n\\frac{1}{\\sqrt{x_2^p}} & \\frac{x_2}{\\sqrt{x_2^p}} \\\\\n\\vdots & \\vdots \\\\\n\\frac{1}{\\sqrt{x_3^p}} & \\frac{x_n}{\\sqrt{x_3^p}}\n\\end{bmatrix}\n\nque não possui um termo constante, portanto não possui intercepto. Os novos modelos são ajustados utilizando a mesma função lm(), porém ajustando o argumento weights = 1/(ntrabalhadores)^p. A tabela com os estimadores e suas características para os modelos sem intercepto são expostas a seguir.\n\n\nCode\nfit_w1 &lt;- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^1, data = supervisores)\nfit_w2 &lt;- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^2, data = supervisores)\nfit_w3 &lt;- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^3, data = supervisores)\n\n\nbind_rows(tidy(fit_w1), tidy(fit_w2), tidy(fit_w3)) %&gt;%\n  mutate(p = rep(1:3, each = 2), r2 = c(\n    summary(fit_w1)$r.squared,NA,\n    summary(fit_w2)$r.squared,NA,\n    summary(fit_w3)$r.squared,NA\n  )) %&gt;%\n  select(p, everything()) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 4,\n    col.names = c(\"p\", \"Explicativa\", \"Estimador\", \"Erro P.\", \"t\", \"p-valor\", \"R2\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\np\nExplicativa\nEstimador\nErro P.\nt\np-valor\nR2\n\n\n\n\n1\n(Intercept)\n7.7739\n6.4302\n1.2090\n0.2380\n0.8475\n\n\n1\nntrabalhadores\n0.1142\n0.0097\n11.7865\n0.0000\nNA\n\n\n2\n(Intercept)\n3.8033\n4.5697\n0.8323\n0.4131\n0.8785\n\n\n2\nntrabalhadores\n0.1210\n0.0090\n13.4454\n0.0000\nNA\n\n\n3\n(Intercept)\n1.5628\n3.7468\n0.4171\n0.6802\n0.8792\n\n\n3\nntrabalhadores\n0.1260\n0.0093\n13.4912\n0.0000\nNA\n\n\n\n\n\n\n\nDe fato, observa-se que o modelo transformado explica em torno de 7% a mais de variância do que o modelo não transformado, para qualquer valor de p dentre os disponíveis.\nOs gráficos de resposta ajustada versus resíduos Studentizados e gráficos normais de probabilidade dos resíduos Studentizados com envelope simulado são expostos a seguir. De fato, utilizando p = 3 parece resultar em melhor comportamento dos resíduos, mas não é possível concluir nada sobre p=2.\n\n\nCode\najuste1 &lt;- tibble(\n  ajustados = fitted(fit_w1),\n  res_stu = stats::rstudent(fit_w1)\n) %&gt;%\n  ggplot(aes(ajustados, res_stu))+\n  geom_point() +\n  theme_bw()+\n  labs(x = \"Resposta ajustada - p = 1\", y = \"Resíduos Studentizados\")\n\najuste2 &lt;- tibble(\n  ajustados = fitted(fit_w2),\n  res_stu = stats::rstudent(fit_w2)\n) %&gt;%\n  ggplot(aes(ajustados, res_stu))+\n  geom_point() +\n  theme_bw()+\n  labs(x = \"Resposta ajustada - p = 2\", y = \"Resíduos Studentizados\")\n\najuste3 &lt;- tibble(\n  ajustados = fitted(fit_w3),\n  res_stu = stats::rstudent(fit_w3)\n) %&gt;%\n  ggplot(aes(ajustados, res_stu))+\n  geom_point() +\n  theme_bw()+\n  labs(x = \"Resposta ajustada - p = 3\", y = \"Resíduos Studentizados\")\n\nplot_grid(ajuste1, ajuste2,ajuste3)\n\n\n\n\n\nQuanto à avaliação da normalidade, utilizando os gráficos de envelope simulado a seguir, p=3 parece resultar na melhor opção.\n\n\nCode\npar(mfrow = c(2,2))\nenvelope_LR(fit_w1, OLS = F, main.title = \"Resíduos com envelope - p = 1\")\nenvelope_LR(fit_w2, OLS = F, main.title = \"Resíduos com envelope - p = 2\")\nenvelope_LR(fit_w3, OLS = F, main.title = \"Resíduos com envelope - p = 3\")\n\n\n\n\n\nConsiderando as possiblidades apontadas, opta-se pelo modelo em que p=3.\n\n\nInterpretação dos coeficientes estimados\nTendo-se optado por p=3, obtemos \\beta_1 = 0.13. Isto significa que o acréscimo de cada trabalhador implicaria no acrescimo de 0.13 supervisor ou, para uma compreensão mais clara, haveria o acréscimo de um supervisor a cada 7.93 trabalhadores.\n\n\nIntervalo confiança\nConstruimos um intervalo de confiança para \\hat{\\beta_G} sob a condição.\n\n\\hat{\\beta_G} \\sim N(\\beta, \\sigma^2(X^{\\top}V^{-1}X)^{-1})\n E obtemos o seguinte intervalo de confiança:\n\n\\hat{\\beta_G} \\, \\pm \\, t_{n-2} \\, \\sqrt{\\hat\\sigma^2 (X^{\\top}V^{-1}X)^{-1})}\n\n\n\nCode\nattach(supervisores)\n\nY &lt;- as.matrix(nsupervisores)\nX &lt;- as.matrix(cbind(rep(1,length(ntrabalhadores)),ntrabalhadores))\nB &lt;- as.matrix(summary(fit_w3)$coefficients[,1])\nV &lt;- diag(ntrabalhadores^3)\nP &lt;- diag(sqrt(ntrabalhadores^3))\nZ &lt;- solve(P)%*%Y\nQ &lt;- solve(P)%*%X\n\nSQT_nc &lt;- t(Y)%*%solve(V)%*%Y %&gt;% as.double()\nSQReg_nc &lt;- t(B)%*%t(X)%*%solve(V)%*%Y %&gt;% as.double()\nSQRes &lt;- SQT_nc-SQReg_nc %&gt;% as.double()\n\ncovar &lt;- as.double(SQRes/(length(nsupervisores)-2))*solve(t(X)%*%solve(V)%*%X)\n\nLS &lt;- coef(fit_w3)[2] + qt(.95, 25)* sqrt(covar[2,2])\nLI &lt;- coef(fit_w3)[2] + qt(.05, 25)* sqrt(covar[2,2])\n\n\nCom limites LI = 0.11 e LS = 0.14.\n\n\nAnálise de variância\nFinalmente, montamos uma tabela de análise de variância:\n\n\nCode\ntabela_anova &lt;- tibble(\n  fonte = c(\"Regressão\", \"Resíduo\", \"Total\"),\n  gl = c(1, 25, 26),\n  SQ = c(SQReg_nc, SQRes, SQT_nc)\n) %&gt;%\n  mutate(QM = SQ/gl)\n\nf0 &lt;- c(tabela_anova$QM[1]/tabela_anova$QM[2], NA,NA)\npval &lt;- c(1-pf(f0, 1, 25))\n\nbind_cols(tabela_anova, f0, pval) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 4,\n    col.names = c(\"Fonte\", \"g.l.\", \"SQ\", \"QM\", \"F\", \"p-valor\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\nNew names:\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n\n\n\n\n\nFonte\ng.l.\nSQ\nQM\nF\np-valor\n\n\n\n\nRegressão\n1\n8e-04\n8e-04\n1041.385\n0\n\n\nResíduo\n25\n0e+00\n0e+00\nNA\nNA\n\n\nTotal\n26\n8e-04\n0e+00\nNA\nNA\n\n\n\n\n\n\n\nConcluimos pela análise de tabela de variância que nosso modelo transformado é adequado para explicar os dados."
  },
  {
    "objectID": "questao1.html",
    "href": "questao1.html",
    "title": "Questão 1",
    "section": "",
    "text": "Analisaremos o banco de dados prostate do pacote faraway, em que constam dados de estudo prospectivo com 97 homens com câncer de próstata. A seguir são expostas as primeiras seis linhas do banco de dados:\nCode\npacman::p_load(tidyverse, faraway, psych, tidymodels)\n\ndata(prostate)\n\nhead(prostate, 6) %&gt;%\n  select(lpsa, everything())%&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 2\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\nlpsa\nlcavol\nlweight\nage\nlbph\nsvi\nlcp\ngleason\npgg45\n\n\n\n\n-0.43\n-0.58\n2.77\n50\n-1.39\n0\n-1.39\n6\n0\n\n\n-0.16\n-0.99\n3.32\n58\n-1.39\n0\n-1.39\n6\n0\n\n\n-0.16\n-0.51\n2.69\n74\n-1.39\n0\n-1.39\n7\n20\n\n\n-0.16\n-1.20\n3.28\n58\n-1.39\n0\n-1.39\n6\n0\n\n\n0.37\n0.75\n3.43\n62\n-1.39\n0\n-1.39\n6\n0\n\n\n0.77\n-1.05\n3.23\n50\n-1.39\n0\n-1.39\n6\n0\nA variável resposta neste caso é logaritmo do antígeno prostático específico da próstata (lpsa). As covariáveis observadas são: logaritmo do volume do câncer (lcavol), logaritmo do peso da próstata (lweight), idade (age), logaritmo da quantidade de hiperplasia prostática (benignalbph), invasão da vesícula seminal (svi), logaritmo da penetração capsular (lcp), escore de Gleason (gleason), e escore percentual de Gleason 4 ou 5 (pgg45)."
  },
  {
    "objectID": "questao1.html#análise-exporatória",
    "href": "questao1.html#análise-exporatória",
    "title": "Questão 1",
    "section": "Análise exporatória",
    "text": "Análise exporatória\nIniciamos a análise exploratória com uma avaliação gráfica da distribuição das variáveis disponíveis. Aqui, as variáveis age e pgg45 foram separadas para que não distorcessem a escala das demais variáveis ilustradas.\nDentre o primeiro grupo de variáveis, pode-se destacar uma maior assimetria positiva em gleason e lcp, assim como uma dispersão muito pequena em lweight e svi. Quanto às últimas, é esperada uma pequena variação de lweight já que se trata de um órgão humano e svi é uma variável dicotômica.\n\n\nCode\nprostate %&gt;%\n  select(-age, -pgg45)%&gt;%\n  pivot_longer(everything(), names_to = \"variavel\") %&gt;%\n  ggplot(aes(variavel, value))+\n  labs(x = \"\", y = \"\")+\n  geom_boxplot()+\n  stat_summary(fun=mean, geom=\"point\", shape=5, size=2, color=\"black\", fill=\"gray\")+\n  theme_minimal()\n\n\n\n\n\nBoxplot de variáveis do banco de dados\n\n\n\n\nJá em relação à variável age, notamos que a maioria dos indivíduos tem em torno de 60 anos. Ao mesmo tempo, vemos que a maioria dos indivíduos tem menos de 50% de escore percentual de Gleason 4 ou 5.\n\n\nCode\nprostate %&gt;%\n  select(age, pgg45)%&gt;%\n  pivot_longer(everything(), names_to = \"variavel\") %&gt;%\n  ggplot(aes(variavel, value))+\n  labs(x = \"\", y = \"\")+\n  geom_boxplot()+\n  stat_summary(fun=mean, geom=\"point\", shape=5, size=2, color=\"black\", fill=\"gray\")+\n  theme_minimal()\n\n\n\n\n\nBoxplot de idade e escores de Gleason 4 ou 5\n\n\n\n\nA tabela com medidas resumo a seguir aponta as mesmas assimetrias avaliadas anteriormente e desvios-padrão altos – relativamente à escala de cada variável – para pgg45 e lbph. Notamos ainda que os indivíduos tem entre 41 e 79 anos de idade.\n\n\nCode\nmedidas &lt;- describe(prostate)\n\nnomes &lt;- row.names(medidas)\n\nmedidas %&gt;%\n  as_tibble() %&gt;%\n  mutate(vars = nomes) %&gt;%\n  select(vars, mean, median, sd, min, max, skew, kurtosis)%&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 2,\n    col.names = c(\"\", \"Média\", \"Mediana\", \"Desv.Pad\", \"Mín\", \"Máx\", \"Skew.\",\"Kurt.\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\nMedidas resumo da base de dados \n\n\n\nMédia\nMediana\nDesv.Pad\nMín\nMáx\nSkew.\nKurt.\n\n\n\n\nlcavol\n1.35\n1.45\n1.18\n-1.35\n3.82\n-0.24\n-0.60\n\n\nlweight\n3.65\n3.62\n0.50\n2.37\n6.11\n1.18\n5.02\n\n\nage\n63.87\n65.00\n7.45\n41.00\n79.00\n-0.80\n0.96\n\n\nlbph\n0.10\n0.30\n1.45\n-1.39\n2.33\n0.13\n-1.75\n\n\nsvi\n0.22\n0.00\n0.41\n0.00\n1.00\n1.36\n-0.16\n\n\nlcp\n-0.18\n-0.80\n1.40\n-1.39\n2.90\n0.71\n-1.01\n\n\ngleason\n6.75\n7.00\n0.72\n6.00\n9.00\n1.22\n2.36\n\n\npgg45\n24.38\n15.00\n28.20\n0.00\n100.00\n0.94\n-0.37\n\n\nlpsa\n2.48\n2.59\n1.15\n-0.43\n5.58\n0.00\n0.43"
  },
  {
    "objectID": "questao1.html#ajuste-de-modelo",
    "href": "questao1.html#ajuste-de-modelo",
    "title": "Questão 1",
    "section": "Ajuste de Modelo",
    "text": "Ajuste de Modelo\nIniciamos um ajuste de regressão linear utilizando a função lm() do pacote stats utilizando todas as variáveis. Para seleção de algum modelo com melhor desempenho sem a estimação de todos os parâmetros, utilizamos MASS::stepAIC() para uma seleção automática de covariáveis e terminamos com o seguinte modelo, que apresenta R^2= 0.64:\n\n\\begin{aligned}\n  \\hat{\\text{lpsa}} &= \\hat{\\beta_0} + \\hat{\\beta_1} \\, \\text{lcavol} +\\hat{\\beta_2} \\, \\text{lweight} + \\hat{\\beta_3} \\, \\text{age} + \\hat{\\beta_4} \\, \\text{lbph} + \\hat{\\beta_5} \\, \\text{svi} \\\\\n   &= 0,951 + 0,565 \\, \\text{lcavol} + 0,423 \\, \\text{lweight} -0,014 \\, \\text{age} + 0,111 \\, \\text{lbph} + 0,721 \\, \\text{svi}.\n\\end{aligned}\n\nNo entanto, é possível ver na tabela a seguir que nem todos os coeficientes podem ser considerados significantes, de modo que reduzimos ainda mais o modelo.\n\n\nCode\ntidy(fit1) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 3\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.951\n0.832\n1.143\n0.256\n\n\nlcavol\n0.566\n0.075\n7.583\n0.000\n\n\nlweight\n0.424\n0.167\n2.539\n0.013\n\n\nage\n-0.015\n0.011\n-1.385\n0.170\n\n\nlbph\n0.112\n0.058\n1.927\n0.057\n\n\nsvi\n0.721\n0.209\n3.449\n0.001\n\n\n\n\n\n\n\nCode\nfit2 &lt;- lm(lpsa ~ lcavol + lweight + svi , data = prostate)\n\n\nQuando consideramos apenas as covariáveis para as quais temos significância a 5%, ficamos com um modelo final expresso pela equação a seguir e temos R^2= 0.63, o que significa que esse percentual da variância dos dados podem ser explicados pelo modelo.\n\n\\begin{aligned}\n  \\hat{\\text{lpsa}} &= \\hat{\\beta_0} +  \\hat{\\beta_1} \\, \\text{lcavol} + \\hat{\\beta_2} \\, \\text{lweight} + \\hat{\\beta_5} \\, \\text{svi} \\\\\n   &= -0,268  + 0,551 \\, \\text{lcavol} + 0,508 \\, \\text{lweight}  + 0,666 \\, \\text{svi}.\n\\end{aligned}\n\n\nAnálise de Variância\nPara construir a tabela da análise de variância, construimos primeiro o modelo apenas com o intercepto e depois comparamos ao modelo selecionado na etapa anterior. A tabela de ANOVA é apresentada na tabela a seguir.\n\n\nCode\n#modelo só com intercepto\nfit0 &lt;- lm(lpsa ~ 1, data = prostate)\n\n#tabela diretamente de anova()\ntabela &lt;- anova(fit2, fit0) %&gt;% \n  as_tibble() %&gt;%\n  select(\"gl\" = Res.Df, \"SQ\" = RSS)\n\n\n#montando a fonte de variacao do modelo\nmodelo &lt;- tibble(gl = nrow(prostate) - tabela$gl[1] -1, SQ = tabela$SQ[2] - tabela$SQ[1])\n\n#arrumando a tabela\ntabela_qm &lt;- tabela %&gt;%\n  bind_rows(modelo) %&gt;%\n  arrange(gl) %&gt;%\n  mutate(Fonte = c(\"Regressão\", \"Resíduo\", \"Total\"),\n         QM = SQ/gl) %&gt;%\n  select(Fonte, everything())\n\n# Calculando F_0 e pvalor do teste\nF0 &lt;- c(tabela_qm$QM[1]/tabela_qm$QM[2], NA, NA)\npval &lt;- pf(F0, df1=tabela_qm$gl[1], df2=tabela_qm$gl[2], lower.tail = FALSE)\n\ntabela_anova &lt;- tabela_qm %&gt;% bind_cols(\"F\" = F0,\"pval\" = pval)\n\noptions(knitr.kable.NA = '')\n\ntabela_anova %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 2,\n    col.names = c(\"Fonte\", \"g.l.\", \"SQ\", \"QM\", \"F\", \"p-valor\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\nFonte\ng.l.\nSQ\nQM\nF\np-valor\n\n\n\n\nRegressão\n3\n80.13\n26.71\n51.99\n0\n\n\nResíduo\n93\n47.78\n0.51\n\n\n\n\nTotal\n96\n127.92\n1.33\n\n\n\n\n\n\n\n\n\nConclui-se, pelo resultado do teste F (o p-valor apresentado na tabela é muito próximo de zero e por isso é arredondado para zero) que há pelo menos um dos coeficientes do modelo diferente de zero a um nível inferior a 0,001% de significância.\n\n\nAvaliação da variância\nComparando os valores ajustados da resposta com os resíduos Studentizados, os pontos parecem ter comportamento aleatório em torno do zero, sem indicação de mudança na variação dos pontos em algum intervalo de \\hat{Y}. Podemos dizer portanto que não há indícios contra a suposição de homocedasticiade do modelo.\n\n\nCode\ntibble(\n  ajustados = fitted(fit2),\n  res_stu = stats::rstudent(fit2)\n) %&gt;%\n  ggplot(aes(ajustados, res_stu))+\n  geom_point() +\n  theme_bw()+\n  labs(x = \"Resposta ajustada\", y = \"Resíduos Studentizados\")\n\n\n\n\n\n\n\nSuposição de normalidade\nAvalia-se a suposição de normalidade dos resíduos comparando os resíduos Studentizados com os quantis da distribuição Normal, tal qual um qqplot, porém com uma banda de confiança obtida via bootstrap paramétrico.\nObserva-se que alguns dos pontos de fato parecem margear os limites da banda de confiança, mas estão muito próximos. Afirma-se portanto que não há fuga da suposição de normalidade dos resíduos e, portanto, da resposta.\n\n\nCode\nsource(\"envelope_function.R\")\n\nenvelope_LR(fit2, OLS = T, main.title = \"Gráfico dos resíduos com envelope\") \n\n\n\n\n\n\n\nInterpretação do modelo\nForam conferidos, portanto, os pressupostos do modelo, de modo que se pode modelar o logaritmo do antígeno prostático específico (lpsa) em função de (0) uma média, o intercepto do modelo, (1) logaritmo do volume do câncer (lcavol), (2) logaritmo do peso da próstata (lweight) e (5) invasão ou não da vesícula seminal (svi) da seguite forma:\n\n\\begin{aligned}\n  \\hat{\\text{lpsa}} &= \\hat{\\beta_0} +  \\hat{\\beta_1} \\, \\text{lcavol} + \\hat{\\beta_2} \\, \\text{lweight} + \\hat{\\beta_5} \\, \\text{svi} \\\\\n   &= -0,268  + 0,551 \\, \\text{lcavol} + 0,508 \\, \\text{lweight}  + 0,666 \\, \\text{svi}.\n\\end{aligned}\n\nEm outros termos, o aumento em uma unidade em alguma das covariáveis X_i aumenta em \\beta_i o logaritmo do antígeno prostático específico.\n\n\nIntervalos de confiança para \\beta_i\n\n\nCode\nX &lt;- prostate %&gt;%\n  select(lcavol, lweight, svi) %&gt;%\n  as.matrix()\n\ninvXtX &lt;- solve(t(X) %*% X)\n\n\nConsideramos que neste caso \\hat{\\beta} \\sim N_3\\left( \\beta, \\sigma^2(X^\\top X)^{-1} \\right). Usamos \\hat{\\sigma^2} como o quadrado médio do resíduo para estimar \\sigma^2. A variância de \\hat{\\beta} portanto é\n\n\\hat{\\sigma^2}(X^\\top X)^{-1} = 0.51 \\cdot\n\\begin{bmatrix}\n0.0108 & -0.0030 & -0.0161\\\\\n-0.0030 & 0.0018 & 0.0008 \\\\\n-0.0161 & 0.0008 & 0.0856\n\\end{bmatrix}\n\ne\n\n\\hat{\\beta_j} \\sim N \\left( \\beta_j, \\hat{\\sigma^2} \\, a_{jj} \\right)\n\nem que a_{jj} é o j-ésimo elemento da diagonal da matriz (X^\\top X)^{-1}.\nConstruimos os intervalos de confiança da seguinte forma\n\nIC\\left( \\hat{\\beta_j}; \\gamma \\right) = \\hat{\\beta_j} \\pm t_{n-k; \\, \\gamma} \\cdot \\sqrt{\\hat{\\sigma^2} \\, a_{jj}}, \\quad n=97, \\, k=3, \\, \\gamma = 0,95\n\ne expomos na tabela a seguir:\n\n\nCode\ntibble(coefs = coef(fit2)[2:4]) %&gt;%\n  mutate(LS = coefs + qt(.975, 94)*diag(invXtX),\n         LI = coefs - qt(.975, 94)*diag(invXtX)) %&gt;%\n  transmute(\n    beta = c(\"beta 1\", \"beta 2\", \"beta 5\"),\n    `[LI, LS]` = paste0(\"[\",round(LI,3), \", \", round(LS, 3),\"]\")) %&gt;%\n  knitr::kable(\n    align = c(\"c\"),\n    booktabs = TRUE,\n    longtable = TRUE,\n    linesep = \"\",\n    escape = FALSE,\n    digits = 2,\n    col.names = c(\"Beta\", \"[LI, LS]\")\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"center\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\")\n\n\n\n\n\nBeta\n[LI, LS]\n\n\n\n\nbeta 1\n[0.53, 0.573]\n\n\nbeta 2\n[0.505, 0.512]\n\n\nbeta 5\n[0.496, 0.836]\n\n\n\n\n\n\n\nNota-se que nenhum dos intervalos compreende o valor 0, de modo que podemos dizer que os coeficientes escolhidos são todos diferentes de zero."
  }
]