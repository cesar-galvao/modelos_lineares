---
title: "Questão 2"
---

Nesta seção, exploraremos dados referentes a 27 estabelecimentos industriais. Tentaremos explicar o número de supervisores em função do número de trabalhadores desses estabelecimentos.

As primeiras seis linhas desse conjunto de dados são expostos na tabela a seguir.

```{r}
pacman::p_load(tidyverse, tidymodels, cowplot)

supervisores <- read.table("supervisores.txt", header = TRUE)

head(supervisores, 6) %>%
  select(nsupervisores, ntrabalhadores) %>%
  knitr::kable(
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

## Análise exploratória

Iniciamos a análise exploratória com a inspeção visual do gráfico de dispersão entre a variável resposta, `nsupervisores`, e a variável explicativa, `ntrabalhadores`.

É notável uma dispersão em formato de cone, o que sugere heteroscedasticidade da variável resposta.

```{r}
ggplot(supervisores, aes(nsupervisores, ntrabalhadores))+
  geom_point()+
  labs(x = "Trabalhadores", y = "Supervisores") +
  theme_bw()
```

Além disso, é possível observar que as distribuições parecem razoavelmente simétricas, porém com leve assimetria positiva. O número de trabalhadores (`r sum(sum(supervisores$ntrabalhadores))`) também é muito superior ao de supervisores (`r sum(supervisores$nsupervisores)`), havendo em média `r round(sum(supervisores$ntrabalhadores)/sum(supervisores$nsupervisores))` trabalhadores por supervisor. Essa razão tem limite entre `r (sort(supervisores$ntrabalhadores/supervisores$nsupervisores))[1]%>% round(1)` e `r (sort(supervisores$ntrabalhadores/supervisores$nsupervisores))[length(supervisores$ntrabalhadores/supervisores$nsupervisores)] %>% round(1)`.

```{r}
supervisores %>%
  select("Supervisores" = nsupervisores, "Trabalhadores" = "ntrabalhadores") %>%
  pivot_longer(cols = everything()) %>%
  ggplot(aes(name, value))+
  geom_boxplot()+
  stat_summary(fun=mean, geom="point", shape=5, size=2, color="black", fill="gray")+
  theme_minimal()+
  theme(axis.title = element_blank())
```


## Ajuste de Modelo

```{r}
fit <- lm(nsupervisores ~ ntrabalhadores, data = supervisores)
```


Ajustamos um modelo de regressão linear simples usando a função `lm()`, cujos estimadores e suas características são espostos a seguir. O coeficiente de determinação do modelo é $R^2=$ `r round(summary(fit)$r.squared,2)`.

```{r}
tidy(fit) %>%
  knitr::kable(
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 4,
    col.names = c("", "Estimador", "Erro P.", "t", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```


```{r}
normalidade <- shapiro.test(fit$residuals)
```


O estimador do modelo tem as suas características dispostas na tabela a seguir. O coeficiente de determinação do modelo é de $R^2=$ `r round(summary(fit)$r.squared,2)`, ou seja, `r round(summary(fit)$r.squared,2)*100`% da variação da variável resposta pode ser explicada pela variável explicativa. 

```{r}
tidy(fit) %>%
  knitr::kable(
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 4,
    col.names = c("", "Estimador", "Erro P.", "t", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

No entanto, este coeficiente seria aplicável a um modelo com resíduos homocedásticos e com distribuição normal. Visualmente, já se trata de um modelo com resíduos heteroscedásticos porém, mediante aplicação de teste Shapiro-Wilk, obtém-se p-valor de `r round(normalidade$p.value,2)`, não sugerindo rejeição da normalidade.

### Análise de resíduos Studentizados

Se montarmos um gráfico de resposta versus resíduos Studentizados vemos novamente indícios para resíduos heteroscedásticos.

```{r}
tibble(
  ajustados = fitted(fit),
  res_stu = stats::rstudent(fit)
) %>%
  ggplot(aes(ajustados, res_stu))+
  geom_point() +
  theme_bw()+
  labs(x = "Resposta ajustada", y = "Resíduos Studentizados")
```

### Avaliação de normalidade da resposta

Uma análise visual do gráfico dos resíduos Studentizados versus quantis da normal demonstram um padrão periódico com diversos pontos fora da banda de confiança. Contrariamente ao teste Shapiro-Wilk, esta avaliação sugere fuga da suposição de normalidade.

```{r}
source("envelope_function.R")

envelope_LR(fit, OLS = T, main.title = "Gráfico dos resíduos com envelope")
```

### Modelos sob Mínimos Quadrados Ponderados

Nesta seção supomos que $Var(Y) = \sigma^2 V$, com $V = diag\{x_1^p, x_2^p, \dots, x_n^p\}$, com $p = 1, 2, 3$. Ou seja, serão ajustados três modelos, transformações do modelo original, decompondo via Cholesky a matriz $V = PP^\top$. O novo modelo é dado por

$$
P^{-1}Y = P^{-1}X\beta + P^{-1}\varepsilon \quad \Rightarrow \quad Z = Q\beta + \eta
$$

De fato, 

$$
X = \begin{bmatrix}
1 & x_1\\
1 & x_2 \\
\vdots & \vdots \\
1 & x_n
\end{bmatrix} \quad \Rightarrow \quad Q = \begin{bmatrix}
\frac{1}{\sqrt{x_1^p}} & \frac{x_1}{\sqrt{x_1^p}}\\
\frac{1}{\sqrt{x_2^p}} & \frac{x_2}{\sqrt{x_2^p}} \\
\vdots & \vdots \\
\frac{1}{\sqrt{x_3^p}} & \frac{x_n}{\sqrt{x_3^p}}
\end{bmatrix}
$$

que não possui um termo constante, portanto não possui intercepto. Os novos modelos são ajustados utilizando a mesma função `lm()`, porém ajustando o argumento `weights` = $1/(ntrabalhadores)^p$. A tabela com os estimadores e suas características para os modelos sem intercepto são expostas a seguir.

```{r}
fit_w1 <- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^1, data = supervisores)
fit_w2 <- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^2, data = supervisores)
fit_w3 <- lm(nsupervisores ~ ntrabalhadores, weights = 1/(ntrabalhadores)^3, data = supervisores)


bind_rows(tidy(fit_w1), tidy(fit_w2), tidy(fit_w3)) %>%
  mutate(p = rep(1:3, each = 2), r2 = c(
    summary(fit_w1)$r.squared,NA,
    summary(fit_w2)$r.squared,NA,
    summary(fit_w3)$r.squared,NA
  )) %>%
  select(p, everything()) %>%
  knitr::kable(
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 4,
    col.names = c("p", "Explicativa", "Estimador", "Erro P.", "t", "p-valor", "R2")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

De fato, observa-se que o modelo transformado explica em torno de 7% a mais de variância do que o modelo não transformado, para qualquer valor de $p$ dentre os disponíveis.

Os gráficos de resposta ajustada versus resíduos Studentizados e gráficos normais de probabilidade dos resíduos Studentizados com envelope simulado são expostos a seguir. De fato, utilizando $p = 3$ parece resultar em melhor comportamento dos resíduos, mas não é possível concluir nada sobre $p=2$.

```{r}
ajuste1 <- tibble(
  ajustados = fitted(fit_w1),
  res_stu = stats::rstudent(fit_w1)
) %>%
  ggplot(aes(ajustados, res_stu))+
  geom_point() +
  theme_bw()+
  labs(x = "Resposta ajustada - p = 1", y = "Resíduos Studentizados")

ajuste2 <- tibble(
  ajustados = fitted(fit_w2),
  res_stu = stats::rstudent(fit_w2)
) %>%
  ggplot(aes(ajustados, res_stu))+
  geom_point() +
  theme_bw()+
  labs(x = "Resposta ajustada - p = 2", y = "Resíduos Studentizados")

ajuste3 <- tibble(
  ajustados = fitted(fit_w3),
  res_stu = stats::rstudent(fit_w3)
) %>%
  ggplot(aes(ajustados, res_stu))+
  geom_point() +
  theme_bw()+
  labs(x = "Resposta ajustada - p = 3", y = "Resíduos Studentizados")

plot_grid(ajuste1, ajuste2,ajuste3)

```

Quanto à avaliação da normalidade, utilizando os gráficos de envelope simulado a seguir, $p=3$ parece resultar na melhor opção.

```{r}
par(mfrow = c(2,2))
envelope_LR(fit_w1, OLS = F, main.title = "Resíduos com envelope - p = 1")
envelope_LR(fit_w2, OLS = F, main.title = "Resíduos com envelope - p = 2")
envelope_LR(fit_w3, OLS = F, main.title = "Resíduos com envelope - p = 3")
```

Considerando as possiblidades apontadas, opta-se pelo modelo em que $p=3$.


### Interpretação dos coeficientes estimados

Tendo-se optado por $p=3$, obtemos $\beta_1 =$ `r round(coef(fit_w3)[2],2)`. Isto significa que o acréscimo de cada trabalhador implicaria no acrescimo de `r round(coef(fit_w3)[2],2)` supervisor ou, para uma compreensão mais clara, haveria o acréscimo de um supervisor a cada `r round(1/(coef(fit_w3)[2]),2)` trabalhadores.


### Intervalo confiança

Construimos um intervalo de confiança para $\hat{\beta_G}$ sob a condição.

$$
\hat{\beta_G} \sim N(\beta, \sigma^2(X^{\top}V^{-1}X)^{-1})
$$
E obtemos o seguinte intervalo de confiança:

$$
\hat{\beta_G} \, \pm \, t_{n-2} \, \sqrt{\hat\sigma^2 (X^{\top}V^{-1}X)^{-1})}
$$

```{r, include = FALSE}
attach(supervisores)

Y <- as.matrix(nsupervisores)
X <- as.matrix(cbind(rep(1,length(ntrabalhadores)),ntrabalhadores))
B <- as.matrix(summary(fit_w3)$coefficients[,1])
V <- diag(ntrabalhadores^3)
P <- diag(sqrt(ntrabalhadores^3))
Z <- solve(P)%*%Y
Q <- solve(P)%*%X

SQT_nc <- t(Y)%*%solve(V)%*%Y %>% as.double()
SQReg_nc <- t(B)%*%t(X)%*%solve(V)%*%Y %>% as.double()
SQRes <- SQT_nc-SQReg_nc %>% as.double()

covar <- as.double(SQRes/(length(nsupervisores)-2))*solve(t(X)%*%solve(V)%*%X)

LS <- coef(fit_w3)[2] + qt(.95, 25)* sqrt(covar[2,2])
LI <- coef(fit_w3)[2] + qt(.05, 25)* sqrt(covar[2,2])
```

Com limites $LI =$ `r round(LI,2)` e $LS =$ `r round(LS,2)`.


### Análise de variância

Finalmente, montamos uma tabela de análise de variância:

```{r}
tabela_anova <- tibble(
  fonte = c("Regressão", "Resíduo", "Total"),
  gl = c(1, 25, 26),
  SQ = c(SQReg_nc, SQRes, SQT_nc)
) %>%
  mutate(QM = SQ/gl)

f0 <- c(tabela_anova$QM[1]/tabela_anova$QM[2], NA,NA)
pval <- c(1-pf(f0, 1, 25))

bind_cols(tabela_anova, f0, pval) %>%
  knitr::kable(
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 4,
    col.names = c("Fonte", "g.l.", "SQ", "QM", "F", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Concluimos pela análise de tabela de variância que nosso modelo transformado é adequado para explicar os dados.
